<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Exploring Weight decay and Spectral Normalization in MLPs and Residual networks | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Project proposal for Spectral normalization related final project for 6.s898, Fall 2023."/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/WeightDecaySpecNormEffects/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> </head> <d-front-matter> <script async type="text/json">{
      "title": "Exploring Weight decay and Spectral Normalization in MLPs and Residual networks",
      "description": "Project proposal for Spectral normalization related final project for 6.s898, Fall 2023.",
      "published": "November 8, 2023",
      "authors": [
        {
          "author": "Preston Hess",
          "authorURL": "https://rphess.cargo.site/",
          "affiliations": [
            {
              "name": "MIT BCS and EECS",
              "url": ""
            }
          ]
        },
        {
          "author": "Andrew Hutchison",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT EECS",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Exploring Weight decay and Spectral Normalization in MLPs and Residual networks</h1> <p>Project proposal for Spectral normalization related final project for 6.s898, Fall 2023.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#relevance-and-investigation">Relevance and Investigation</a></div> <div><a href="#proposed-methods">Proposed Methods</a></div> </nav> </d-contents> <h2 id="relevance-and-investigation">Relevance and Investigation</h2> <p>Weight normalization is important in machine learning for two reasons. Weight normalization prevents weights from getting too large, thereby avoiding exploding gradients and introducing numerical stability while training. Furthermore, it can prevent overfitting to the data. One popular method for weight normalization is weight decay. Weight decay is a regularization technique that penalizes the Frobenius Norm of the weight matrices. It is implemented through adding a term proportional to the sum of the Frobenius Norm of the weight matrices to the loss function, thereby increasing loss when weights get larger. One of the issues with merely regularizing with the Frobenius Norm or performing Frobenius normalization of weight matrices is that it imposes a more strict constraint than we want: it enforces that the sum of singular values is one, which can lead to weight matrices of rank one (Miyato et al. 2018). Another issue is that the sum of the Frobenius norm scales with depth, potentially causing deeper networks to force smaller values than necessary upon their weight matrices.</p> <p>A more novel method that addresses this is spectral normalization, which instead focuses on initializing and updating the weight matrices in a way that preserves their spectral norm, keeping it around the square root of the change in layer size. This deals with some issues of weight decay by focusing on the norms of individual weight matrices during their update, rather than summing the effect of all weight matrices in the loss function. Thus far, it seems to allow for a more stable learning algorithm and helps to produce more predictable scaling of models and improve feature learning.</p> <p>We want to further explore the effects of weight decay and spectral normalization on different architectures through a comparative study on Multi-Layer Perceptrons (MLPs) and Residual Neural Networks (ResNets). We aim to investigate two general areas related to the spectral norm: spectral normalization versus Weight Decay, and differences in the influence of spectral normalization on MLPs and Residual Neural Networks. We aim to understand how the spectral norm of weight matrices change over time, how the rank of weight matrices is affected by each technique, and how they affect overall model performance. Furthermore, we want to see how the distribution of singular values changes across architectures, determining if certain types of architectures can benefit more from spectral normalization than another.</p> <h2 id="proposed-methods">Proposed Methods</h2> <p>We will train MLPs and ResNets of two depths- medium and large- on a simple image classification task. Within each of these 4 classes we will train each network with no weight normalization to act as a baseline, with weight decay, and with spectral normalization. During training we will keep track of the metrics of interest at the end of each epoch. We plan to train our models using Preston’s access to MIT BCS’s OpenMind compute cluster, where we will have access to extensive compute resources that should make training time trivial.</p> <p>Instead of only investigating the effects of our independent variables on accuracy, we will record the distribution of singular values across epochs and trials to see if we can find any important trends in terms of predicting performance. More importantly, this investigation will help illuminate any underlying mechanistic reasons for certain properties of our network. We will also record how the rank of weight matrices changes over time for different normalization methods and architectures. More discussion is needed with our advisor in order to understand the significance of low rank weight matrices and how we might incorporate this into our analysis.</p> <hr/> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/_biblography/2023-11-08-WeightDecaySpecNormEffects.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>