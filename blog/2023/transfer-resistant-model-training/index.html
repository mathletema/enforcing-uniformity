<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Project Proposal - Transfer Resistant Model Training | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="This blog post is our project proposal for a method of training neural networks that are resistant to transfer learning techniques."/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/transfer-resistant-model-training/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> </head> <d-front-matter> <script async type="text/json">{
      "title": "Project Proposal - Transfer Resistant Model Training",
      "description": "This blog post is our project proposal for a method of training neural networks that are resistant to transfer learning techniques.",
      "published": "November 9, 2023",
      "authors": [
        {
          "author": "Ryan Yang",
          "authorURL": "https://www.google.com/url?sa=i&url=https%3A%2F%2Fmanipulation.csail.mit.edu%2FFall2023%2Findex.html&psig=AOvVaw3MuJLCZwr7MxMiaaFQTBeC&ust=1699601771753000&source=images&cd=vfe&opi=89978449&ved=0CBIQjRxqFwoTCNil45C0toIDFQAAAAAdAAAAABAH",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        },
        {
          "author": "Evan Seeyave",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Project Proposal - Transfer Resistant Model Training</h1> <p>This blog post is our project proposal for a method of training neural networks that are resistant to transfer learning techniques.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#related-work">Related Work</a></div> <div><a href="#experiment">Experiment</a></div> <div><a href="#analysis">Analysis</a></div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>We are interested in robustness of models against fine-tuning or transfer learning. The motivating example is as follows: suppose there is a model trained to be capable of classifying a dataset. An external agent wants to train a model to classify a different dataset for a possibly malicious purpose. With transfer learning, this is possible and performs well by replacing and retraining just the last few model layers <d-cite key="zhuang2020comprehensive"></d-cite>. We aim to investigate a method of training the model to be capable of classifying the original set of classes but is more difficult to transfer to different datasets. Thus we aim to answer the question: How can we train a model such that it is robust to transfer learning on a new dataset?</p> <h2 id="related-work">Related Work</h2> <p>The authors are not aware of previous work in the realm of improving robustness of models against transferability. There have been previous analyses of transfer learning, most commonly found in convolutional neural networks <d-cite key="zhuang2020comprehensive"></d-cite>. A related problem is machine unlearning which takes a trained model and attempts to make the model forget defined points of information <d-cite key="cao2015towards"></d-cite>. However, our problem setting is different in that we wish to prevent learning undesirable pieces of information from the beginning of training as opposed to forgetting after training.</p> <h2 id="experiment">Experiment</h2> <p>The problem settings above relating to transfer learning and machine unlearning often involve large convolutional neural networks (CNNs) or language models. Due to computational constraints, this will not be feasible for this project. Rather, we will investigate a toy problem setting. The toy setting will focus on a shallow CNN with the MNIST dataset. We will split the MNIST dataset into two sets, a “desirable” set and “undesirable” set. For example, the “desirable” set contains images with labels from 0 to 4. The undesirable set will contain all images with labels from 5 to 9. We aim to train a CNN that successfully classifies the images in the “desirable” set but is difficult to then be trained on the “undesirable” set. Specifically, we aim to find an intervention to training on the “desirable” set such that replacing and retraining the last layer of the CNN for the “undesirable” set, takes longer than replacing and retraining the last layer of a CNN without any intervention. Note that for our problem setting, we assume we have access to samples and classes in the “undesirable” set when training with an intervention on the “desirable” set.</p> <h2 id="analysis">Analysis</h2> <p>The most straightforward benchmark is the performance of the model with the intervention versus the model without the intervention after transferring to the “undesirable” set. Our objective is that the performance of the model with the intervention on the “undesirable” set is significantly worse than the model without the intervention. Qualitatively, we aim to provide figures of features learned by the CNN with the intervention and without the intervention. Specifically, we hope to show some features learned in the CNN with intervention are qualitatively different from the features learned in the CNN without intervention using methods such as Grad-CAM <d-cite key="selvaraju2017grad"></d-cite>.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/2023-11-09-transfer-resistant-model-training.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>