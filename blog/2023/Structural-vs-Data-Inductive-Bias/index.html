<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Structural vs Data Inductive Bias | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Class project proposal"/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/Structural-vs-Data-Inductive-Bias/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "Structural vs Data Inductive Bias",
      "description": "Class project proposal",
      "published": "November 9, 2023",
      "authors": [
        {
          "author": "Gabriel Gallardo",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT, Cambridge",
              "url": ""
            }
          ]
        },
        {
          "author": "Tony Jiang",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT, Cambridge",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Structural vs Data Inductive Bias</h1> <p>Class project proposal</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#motivation">Motivation</a></div> <div><a href="#research-question">Research Question</a></div> <div><a href="#methodology">Methodology</a></div> </nav> </d-contents> <h2 id="motivation">Motivation</h2> <p>The transformative impact of vision transformer (ViT) architectures in the realm of deep learning has been profound, with their applications swiftly extending from computer vision tasks, competing with traditional neural network architectures like convolutional neural networks (CNNs). Despite their success, the intricacies of how architectural variations within ViTs influence their performance under different data conditions remain largely uncharted. Unraveling these subtleties holds the promise of not only enhancing the efficiency and effectiveness of ViTs but also of offering a window into the broader question of structural inductive biases in deep learning models.</p> <p>The paper “Data-induced constraints versus model-induced structural inductive bias” [1]<d-cite key="reference1"></d-cite> presents a thorough analysis of the benefits of data augmentations on model performance, especially when facing out-of-distribution data. It quantifies the trade-off between augmented and real data and suggests that augmentations can sometimes exceed the value of more training data. This research is relevant to our project as it provides a comparative backdrop; while it explores data-induced constraints and the impact of data augmentation, our study aims to extend the understanding to the domain of model-induced inductive biases by examining the impact of architectural variations in vision transformers.</p> <p>ViT could be heavy data-hungry like stated in [2]<d-cite key="reference2"></d-cite>. Which gives us the opportunity to explore how we can change the structure of the architecture in order to achieve high performance even with a limited data set, comparing it with data augmentation presented in [1]<d-cite key="reference1"></d-cite>.</p> <h2 id="research-question">Research Question</h2> <p>This study seeks to dissect the following pivotal questions: How do specific architectural variations within vision transformer models affect their performance. Understand and quantify the tradeoff between the changes in the architecture and the amount of training data. Our hypothesis is that with some appropriate architectural changes, we would not need as much training data and still achieve the same result.</p> <h2 id="methodology">Methodology</h2> <p>We will start with a standard Vision Transformer architecture as our baseline. From here, we will introduce variations to the architecture, specifically in the attention mechanisms. We want to test different types of attention layers (such as local, global, and sparse attention layer) and explore additional mechanism changes (such as attention augmentation, gating, etc.) [3]<d-cite key="reference3"></d-cite>.</p> <p>Each model will undergo training and evaluation on the Cipher-10 dataset. To appraise the models’ performance, we will use measurement metrics including accuracy and training/inference time. The experimental design will encompass training with and without data augmentation to discern the impact of data variety on the architectural efficacy.</p> <h2 id="reference">Reference</h2> <p>[1] Data-induced constraints versus model-induced structural inductive bias (https://arxiv.org/pdf/2210.06441.pdf)</p> <p>[2] Training Vision Transformers with Only 2040 Images (https://arxiv.org/pdf/2201.10728.pdf)</p> <p>[3] Distilling Inductive Bias: Knowledge Distillation Beyond Model Compression (https://arxiv.org/ftp/arxiv/papers/2310/2310.00369.pdf)</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/2023-11-09-Structural-vs-Data-Inductive-Bias.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>