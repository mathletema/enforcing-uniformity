<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Interpreting decision transformers - world models and feature | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Staging website for the 2023 ICLR Blogposts track "/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/interpreting-world-models/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> </head> <d-front-matter> <script async type="text/json">{
      "title": "Interpreting decision transformers - world models and feature",
      "description": "",
      "published": "November 8, 2023",
      "authors": [
        {
          "author": "Uzay Girit",
          "authorURL": "https://uzpg.me",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        },
        {
          "author": "Tara Rezaei",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Interpreting decision transformers - world models and feature</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <h3 id="goal-of-the-project">Goal of the project:</h3> <p>Decision transformers allow us to bypass the need to assign long term credits and rewards as well as make use of the existing transformer frameworks, bridging the gap between agents and unsupervised learning. Getting trajectories from a trained RL agent, we can then use LLM interpretability techniques to understand these models and how they solve decision making problems. This is more and more crucial as large transformer models become capable of more complicated tasks and are used as decision making agents.</p> <h3 id="potential-questions-to-answer">Potential Questions to answer</h3> <ul> <li>How do deep learning agents/DTs form world models and how can we interpret those abstractions?</li> <li>How do DTs simulate agents to match different levels of performance/different objectives?</li> <li>What patterns can we notice here across tasks and what does this tell us about DNN agents?</li> <li>How are these representations used by the model to complete the task?</li> <li>How do they compare to RL agents in terms of performance, training, compute etc.</li> <li>How much can patterns and dynamics in the agents we interpret tell us about larger models and language modeling?</li> </ul> <h3 id="potential-experiments-and-analysis">Potential experiments and analysis</h3> <ul> <li>run a sparse autoencoder on a decision transformer on different tasks</li> <li>see what what representational patterns we see across tasks</li> <li>analyze through ablations and explore how the model is influenced by the Reward To Go token</li> <li>look at attention patterns and how they relate to the action space</li> </ul> <h3 id="uncertainties">Uncertainties</h3> <ul> <li>In practice, how tractable will the interpretation of world representations be in the framework of sequence modeling?</li> <li>Should we approach this in the frame of transformers for sequence modeling or explore latent world representations like the <em>World Models</em> paper? Maybe the two can be combined?</li> <li>Is it useful to see how different encodings of the data induce different strategies?</li> <li>Is it feasble to aim for automating any part of the pipeline like feature labeling with GPT4, etc <h3 id="related-work">Related work:</h3> </li> <li><a href="https://arxiv.org/abs/2106.01345">Decision Transformers</a></li> <li><a href="https://worldmodels.github.io/">World Models</a></li> <li><a href="https://arxiv.org/abs/2210.13382">Emergent world representations</a></li> <li><a href="https://transformer-circuits.pub/2023/monosemantic-features">Anthropic sparse auto-encoders for LLM interpretability</a></li> <li><a href="https://www.lesswrong.com/posts/bBuBDJBYHt39Q5zZy/decision-transformer-interpretability">Decision Transformers interpretablity</a></li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>