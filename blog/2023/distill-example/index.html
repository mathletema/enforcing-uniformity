<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>GINTransformer vs. Bias | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Your blog post's abstract. This is an example of a distill-style blog post and the main elements it supports."/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/distill-example/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "GINTransformer vs. Bias",
      "description": "Your blog post's abstract. This is an example of a distill-style blog post and the main elements it supports.",
      "published": "November 10, 2023",
      "authors": [
        {
          "author": "Yeabsira Moges",
          "authorURL": "https://www.linkedin.com/in/yeabsira-moges/",
          "affiliations": [
            {
              "name": "AI-DS, MIT",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>GINTransformer vs. Bias</h1> <p>Your blog post's abstract. This is an example of a distill-style blog post and the main elements it supports.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#proposal">Proposal</a></div> </nav> </d-contents> <h2 id="proposal">Proposal</h2> <p>The first piece of information that a person recieves about a given topic determines their belief as a whole on said topic. This is shown in expirements where participants beliefs on several topics were challenged with empirical evidence against their beliefs. Studies consistently show that one a person has their mind made up, it is significantly more difficult to change their mind everytime you challenge them on it. Every interaction solidifies their belief. This is epseically important in the context of the social media era we are living in. A lot of the time, people’s first impressions over a given event gets primed by what they see about it on theif feeds. This is coming to determine more and more discourse, and especially so when global events occur and those under duress can now more broadly share their stories and struggles. While good, we also have to contend with oppositional, orpessive forces using thise to boon their politic. Being able to determine the source of a given topic, or being able to filter through accounts with troublesome history, would bridge the misinformation gap that has always been a problem long before the social networks of the day.</p> <p>To measure this information flow, I propose using a GIN-Based Transformer implimentation to tackle misinformation detection and tracking. The dataset will be constructed from a few years of social media activity in clusters between active users. While the age dunamics across social media apps vary greatly, I predict that a similar trend in misinformation will appear once we abstract away all the noise. I am choosing to implement this using a GIN because I want to take advantage of the network architectures isomorphism property to create non-sparse dense connections for the transformer network to take advantage of to the fullest with multi-headed attention. Each node in the network will comprise tweets and character profiles attached to them, giving context for the post content. I want to exploit this structure to determine the underlying trends that determine communication online.</p> <p>Detecting misinformation is hard. The problem on in the internet age is that detecting misinformation is akin to detecting whether a given claim is true or not, esentially lie detection. This, understandably is really difficult to do even with fact checkers because sometimes, there simply is no one that knows what the whole truth is. Instead of trying to tackle misinformation directly, this proposed approach works to analyze underlying trends in the profiles of people that typically engage in spreading misinformation, and the typical structure that said misinformation takes–a metric i define as information density. Information density will serve to measure the level to which there is a correspondence between the models measure of the veracity of a given claim and the models measure of the profile said text came from.</p> <p>I am hoping to find a robust way to compute the information density of a given account, text pair and use that to determine how trustworthy a given claim is based on previous percieved patterns. In additon to the architecture above, I will be using conditional prompting to augment my data and will finetune my transformer network for the tweets using Distilbert. I want the model to be as light weight and portable as possible, as such I want the predictive ability of my network to not be costly.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/2023-11-10-distill-example.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>