<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Project Proposal | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="This project aims to study the universality of features in LLMs by studying sparse autoencoders trained on similar layers of different models."/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/universal-features/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "Project Proposal",
      "description": "This project aims to study the universality of features in LLMs by studying sparse autoencoders trained on similar layers of different models.",
      "published": "November 9, 2023",
      "authors": [
        {
          "author": "Misha Gerovitch",
          "authorURL": "https://www.linkedin.com/in/michael-gerovitch-2010a61b0/",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        },
        {
          "author": "Asher Parker-Sartori",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Project Proposal</h1> <p>This project aims to study the universality of features in LLMs by studying sparse autoencoders trained on similar layers of different models.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#setup">Setup</a></div> <div><a href="#experiments">Experiments</a></div> <ul> <li><a href="#same-models-early-layer">Same models, early layer</a></li> <li><a href="#same-models-additional-experiments">Same models, additional experiments</a></li> <li><a href="#different-models">Different models</a></li> <li><a href="#model-stitching">Model stitching</a></li> <li><a href="#comparing-representations">Comparing representations</a></li> </ul><div><a href="#acknowledgements">Acknowledgements</a></div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>The internal components of LLMs are not well understood. One of the main barriers to understanding how LLMs represent information is the effect of polysemanticity, where a single neuron is activates for many different concepts (e.g. academic citations, English dialogue, HTTP requests, and Korean text), a result of a high-dimensional space of concepts being compressed into the space of a neural network (for transformers, this is in the residual stream or layers of an MLP.) Sparse autoencoders, a form of dictionary learning, help to linearly disentangle polysemantic neurons into individual features that are ideally more interpretable <d-cite key="cunningham2023sparse"></d-cite> <d-cite key="bricken2023monosemanticity"></d-cite>. We aim to train sparse autoencoders to identify similarities between layers of different models, for example the first layers of two trained models with identical architectures but different starting seeds.</p> <p>Once we have the sparse autoencoders, we will compare the activation distributions on different inputs. If same-architecture models have similar performance on predicting training data, we expect that their activation distributions may be similar. We aim to study how well the features match up at different layers and between various models. We then can ask more complex question:</p> <ul> <li>Do (same architecture) models have similar feature representations at various layers?</li> <li>Do different architecture model have similar feature representations at various layers?</li> <li>What if the layers are different sizes but in the same model family? What if they are in different model families?</li> <li>Do models trained on different data have similar feature representations?</li> <li>How can we measure similarity between representations?</li> <li>Can we use this to improve model stiching techniques?</li> </ul> <h2 id="setup">Setup</h2> <p>We have started looking at <a href="https://github.com/HoagyC/sparse_coding">Hoagy Cunningham’s codebase</a> for training autoencoders that they used for their initial paper <d-cite key="cunningham2023sparse"></d-cite>.</p> <p><a href="https://github.com/neelnanda-io/1L-Sparse-Autoencoder">Neel Nanda also has some starter code</a>.</p> <p>We are planning to try a range of different models from Pythia-160m to Llama2-7b (/-chat). We have relatively easy access to the models through the <a href="https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html">TransformerLens library</a>, but are looking for other sources of models in case we need them.</p> <p>We understand that training sparse autoencoders takes time and resources and are accounting for this taking us a good chunk of our time initially. We are connected with other groups, including Logan Riggs-Smith from the original sparse autoencoders paper, who have experience training the autoencoder. We are also considering sharing our learned representations between multiple groups working on this research to facilitate faster progress on projects that rely on trained autoencoders. This would allow us to focus more on running experiments and testing our additional hypotheses.</p> <p>We have access to compute resources supported by MIT AI Alignment.</p> <h2 id="experiments">Experiments</h2> <p>Here are a few possible experiments we could run:</p> <h3 id="same-models-early-layer">Same models, early layer</h3> <p>The most basic version of this experiment is to take an early residual stream layer of a transformer and train a sparse autoencoder on it for two models that are exactly the same except for the starting seed. Afterwards, we run a bunch of inputs through the autoencoder to get the activation distributions. Once we have the activation distrubitions, we can compare them (see “Comparing representations” section below for discussion.)</p> <h3 id="same-models-additional-experiments">Same models, additional experiments</h3> <ul> <li>We can try looking layers of models trained with different data (but still have the same architecture)</li> <li>We can look at layers of RLHF-ed (chat) model vs the not fine-tuned model</li> <li>We can look at later layers of a model (e.g. in MLP)</li> <li>We can vary which model we do this on (e.g. Pythia vs Llama)</li> </ul> <h3 id="different-models">Different models</h3> <p>A starting point here would be looking at models in the same family but have different parameter count. It is trickier to construct an experiment here since layers may be different sizes. The easiest test would be to find two layers that have the same size and compare the autoencoder-learned representations of those layers. Alternatively, we could investigate if more information is stored in a single layer of a smaller model than a larger model or if the information from one layer of a larger model is spread between two of smaller one.</p> <h3 id="model-stitching">Model stitching</h3> <p>(1) Can we stitch together two model (with a trained weight matrix) right before a sparse autoencoder (that was pre-trained before stitching) that would allow us to extract useful features from the left-stitched model using the right-stitched sparse autoencoder?</p> <p>(2) Can the representations somehow help us figure out where in the model is a good place to stitch two models to minimize the amount of training needed to get good performance? Can we understand what existing model stitching methods work well?</p> <h3 id="comparing-representations">Comparing representations</h3> <p>The simplest, and most desirable, comparison of representations would be finding the permuation matrix of one that most closely yields the other, thus finding a one to one feature mapping. However, this may not be possible. Another method would involve training a weight matrix between the autoencoders, perhaps with regularization that promotes sparsity.</p> <p>Model stitching can also be a method of comparing neural representations <d-cite key="Bansal2021stitching"></d-cite>.</p> <h2 id="acknowledgements">Acknowledgements</h2> <p>Special thanks to Sam Marks for suggesting the initial experiment ideas and to <a href="https://www.mitalignment.org/">MIT AI Alignment</a> for providing connections with mentorship and compute resources.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/2023-11-09-universal-features.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>