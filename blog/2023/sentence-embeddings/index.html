<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Sentence Embeddings | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Large models, such as large language or vision models, are typically used to obtain embeddings of data, such as text or images. The embeddings are very rich and encode semantic information about the objects. The embeddings can be then later be used for tasks such as similarity search. However, the cost (both money and environmental) of obtaining the embeddings can be large. Given a dataset, can we query the model at 'very few points' which can later be extrapolated to embeddings for other data without querying the large model again?"/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/sentence-embeddings/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> </head> <d-front-matter> <script async type="text/json">{
      "title": "Sentence Embeddings",
      "description": "Large models, such as large language or vision models, are typically used to obtain embeddings of data, such as text or images. The embeddings are very rich and encode semantic information about the objects. The embeddings can be then later be used for tasks such as similarity search. However, the cost (both money and environmental) of obtaining the embeddings can be large. Given a dataset, can we query the model at 'very few points' which can later be extrapolated to embeddings for other data without querying the large model again?",
      "published": "November 8, 2023",
      "authors": [
        {
          "author": "Alor Sahoo",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        },
        {
          "author": "Sebastian Alberdi",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Sentence Embeddings</h1> <p>Large models, such as large language or vision models, are typically used to obtain embeddings of data, such as text or images. The embeddings are very rich and encode semantic information about the objects. The embeddings can be then later be used for tasks such as similarity search. However, the cost (both money and environmental) of obtaining the embeddings can be large. Given a dataset, can we query the model at 'very few points' which can later be extrapolated to embeddings for other data without querying the large model again?</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#project-proposal">Project Proposal</a></div> <ul> <li><a href="#introduction">Introduction</a></li> <li><a href="#overview">Overview</a></li> <li><a href="#limitations">Limitations</a></li> </ul><div><a href="#citations">Citations</a></div> </nav> </d-contents> <h2 id="proposal">Proposal</h2> <h3 id="introduction">Introduction</h3> <p>Querying general LLMs frequently is often slow and expensive, especially at scale. Our project investigates student-teacher networks, in which we train a less-accurate, but “cheaper” student model by leveraging the knowledge of a more accurate, but expensive, “teacher” model <d-cite key="teacher"></d-cite>. Already, these types of architectures have already been applied to generate lightweight but performant student networks for a variety of different purposes (classification, recognition, generation, etc.) Sentence level embeddings—very large vectors that quantify aspects of its content— are one such data that can be expensive to query from a teacher model. Among other things, these embeddings are useful for quantifying the similarities of different sentences.</p> <h3 id="overview">Overview</h3> <h4 id="methods">Methods</h4> <p>Our project will specifically center on HuggingFace’s <a href="https://www.sbert.net/docs/pretrained_models.html">pre-trained sentence transformer library</a>. We can approximate a “student” network as the less performant, faster “distiluse-base-multilingual-cased-v2 model” and a “teacher” network as the more performant, slower “all-MiniLM-L12-v2” model. The primary goal will be to determine what specific architecture works best for mapping “student” network embeddings to “teacher network embeddings.</p> <p>We will first use the BOOKSUM dataset from HuggingFace (subject to change) and tokenize the sentence appropriately. Then, we will train our various architectures on 10% of the data by querying both the student and teacher models. The remaining 90% of our text dataset is used to test the model’s predictions against the embeddings of the teacher model. While this ratio of training/testing is very skewed, it is representative of the reality that querying the teacher model is expensive. We will use another dataset (to be determined) to validate our model afterward.</p> <p>One obvious metric for our model’s performance is the average reconstruction loss, as measured by Euclidean distance. Another metric is cosine similarity, which gives information on the angle between vectors and is particularly useful at higher dimensional spaces.</p> <h4 id="architectures">Architectures</h4> <p>We plan to investigate the following architectures (subject to change):</p> <ol> <li>Multi-Layer Perceptron (MLP): MLPs are a simple baseline model to start with, especially since they are easy to train and are universal approximators (in theory).</li> <li>Self-Attention Layer: This allows the model to consider context more and focus on different parts of the input more easily than in an MLP, potentially improving performance.</li> <li>Recurrent Neural Nets: RNNs have a weak notion of “memory,” allowing it to create context-aware mappings from one sentence embedding to another.</li> </ol> <h3 id="limitations">Limitations</h3> <p>We acknowledge that our approximation of a student and teacher network are imperfect—especially since our student network was not distilled directly from the teacher one. Also, if our architecture is too resource intensive, then it doesn’t make sense to query the student model and then apply our model, instead of just querying the teacher model directly. Nonetheless, our project investigates interesting aspects of training on limited data.</p> <h2 id="citations">Citations</h2> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/2023-11-08-sentence-embeddings.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>