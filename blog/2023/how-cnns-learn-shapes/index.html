<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>How CNNs learn shapes | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Staging website for the 2023 ICLR Blogposts track "/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/how-cnns-learn-shapes/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "How CNNs learn shapes",
      "description": "",
      "published": "November 9, 2023",
      "authors": [
        {
          "author": "Chloe Hong",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>How CNNs learn shapes</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#background">Background</a></div> </nav> </d-contents> <h2 id="background">Background</h2> <p>One widely accepted intuition is that CNNs combines low-level features (e.g. edges) to gradually learn more complex and abstracted shapes to detect objects while being invariant to positional and translation.</p> <blockquote> <p>As [@kriegeskorte2015deep] puts it, “the network acquires complex knowledge about the kinds of shapes associated with each category. […] High-level units appear to learn representations of shapes occurring in natural images” (p. 429). This notion also appears in other explanations, such as in [@lecun2015deep]: Intermediate CNN layers recognise “parts of familiar objects, and subsequent layers […] detect objects as combinations of these parts” (p. 436). We term this explanation the shape hypothesis. As a result, the final prediction is based on global patterns rather than local features.</p> </blockquote> <p>However, there has been contradictory findings that CNNs trained on off-the-shelf datasets are biased towards predicting the category corresponding to the texture rather than shape. [@geirhos2018imagenet]</p> <p>{% include figure.html path=”assets/img/2023-11-09-how-cnns-learn-shapes/shapetexture.png” class=”img-fluid” %}</p> <p>Going further, previous works have suggested ways to increase the shape bias of CNNs including data augmentation and relabelling. While these works have successfully shown the discriminative bias of CNNs toward certain features, they do not identify how the networks “perception” changes. With this project, I seek to evaluate the bias contained (i) in the latent representations, and (ii) on a per-pixel level.</p> <h2 id="methods">Methods</h2> <p>I choose two approaches from [@geirhos2018imagenet] and [@chung2022shape] that augment the dataset to achieve an increased shape bias in CNNs. To gain a better understanding what type of shape information contained in the network is discriminative, where shape information is encoded, as well as when the network learns about object shape during training, I use an optimization method to visualize features learned at each layer of the trained models. By comparing the original model to the augmented version, and across different augmentation methods, we can evaluate if there is a common pattern in the way CNNs learns shapes and what additional information is most effective in increasing shape bias in CNNs.</p> <h3 id="data-augmentations">Data augmentations</h3> <p>[@geirhos2018imagenet] increased shape bias by augmenting the data with shape-based representations.</p> <table> <thead> <tr> <th>Features</th> <th>Dataset</th> </tr> </thead> <tbody> <tr> <td>image</td> <td>ImageNet</td> </tr> <tr> <td>image + shape</td> <td>ImageNet augmented with line drawings</td> </tr> <tr> <td>shape</td> <td>Line drawings</td> </tr> </tbody> </table> <p>[@chung2022shape] speculates data distribution is the root cause of discriminative biases in CNNs. To address this, they suggested a granular labeling scheme that redesigns the label space to pursue a balance between texture and shape biases.</p> <table> <thead> <tr> <th>Labels</th> <th>Dataset</th> </tr> </thead> <tbody> <tr> <td>categorical</td> <td>ImageNet</td> </tr> <tr> <td>categorical + style</td> <td>ImageNet</td> </tr> </tbody> </table> <h3 id="cnn-feature-visualization">CNN feature visualization</h3> <p>We visualize features that are understood by the CNN model at the layer level using the following optimization framework.</p> <p>{% include figure.html path=”assets/img/2023-11-09-how-cnns-learn-shapes/cnnfeaturevisualization.png” class=”img-fluid” %}</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/2022-11-09-how-cnns-learn-shapes.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>