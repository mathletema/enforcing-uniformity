<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Dynamic Ensemble Learning for Mitigating Double Descent | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Exploring when and why Double Descent occurs, and how to mitigate it through Ensemble Learning."/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/double_descent/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "Dynamic Ensemble Learning for Mitigating Double Descent",
      "description": "Exploring when and why Double Descent occurs, and how to mitigate it through Ensemble Learning.",
      "published": "November 8, 2023",
      "authors": [
        {
          "author": "Mohit Dighamber",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        },
        {
          "author": "Andrei Marginean",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Dynamic Ensemble Learning for Mitigating Double Descent</h1> <p>Exploring when and why Double Descent occurs, and how to mitigate it through Ensemble Learning.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#motivation">Motivation</a></div> <div><a href="#related-work">Related Work</a></div> <div><a href="#methods">Methods</a></div> <ul> <li><a href="#decision-trees">Decision Trees</a></li> <li><a href="#random-forest">Random Forest</a></li> <li><a href="#logistic-regression">Logistic Regression</a></li> <li><a href="#support-vector-machines">Support Vector Machines</a></li> <li><a href="#neural-networks">Neural Networks</a></li> </ul><div><a href="#evaluation">Evaluation</a></div> <ul> <li><a href="#software">Software</a></li> <li><a href="#datasets">Datasets</a></li> <li><a href="#computing-resources">Computing Resources</a></li> <li><a href="#reproducibility-statement">Reproducibility Statement</a></li> </ul> </nav> </d-contents> <h2 id="motivation">Motivation</h2> <p>There are many important considerations that machine learning scientists and engineers must consider when developing a model. How long should I train a model for? What features and data should I focus on? What exactly is an appropriate model size? This last question is a particularly interesting one, as there is a bit of contention regarding the correct answer between different schools of thought. A classical statistician may argue that, at a certain point, larger models begin to hurt our ability to generalize, whereas a modern machine learning scientist may contest that a bigger model is always better. In reality, neither of these ideas are completely correct in practice, and empirical findings demonstrate some combination of these philosophies.</p> <p>This brings us to the concept known as <strong>Double Descent</strong>. Double Descent is the phenomenon where, as a model’s size is increased, test loss increases after reaching a minimum, then eventually decreases again, potentially to a new global minimum. This often happens in the region where training loss becomes zero (or whatever the ’perfect’ loss score may be), which can be interpreted as the model ’memorizing’ the training data given to it. The question of ’how big should my model be?’ is key to the studies of machine learning practitioners. While many over-parameterized models can miraculously achieve lower test losses than the initial test loss minimum, it is fair to ask if the additional time, computing resources, and electricity used make the additional performance worth it. To study this question in a novel way, we propose incorporating <strong>Ensemble Learning</strong>.</p> <p>Ensemble Learning is the practice of using several machine learning models in conjunction to potentially achieve even greater accuracy on test datasets than any of the individual models. Ensemble Learning is quite popular for classification tasks due to this reduced error empirically found on many datasets. To our knowledge, there is not much literature on how Double Descent is affected by Ensemble Learning versus how the phenomenon arises for any individual model.</p> <p>We are effectively studying two different types of model complexity: one that incorporates higher levels parameterization for an individual model, and one that uses several models in conjunction with each other. We aim to demonstrate how ensemble learning may affect the onset of the double descent phenomenon. Possible results may include that the phenomenon occurs at a smaller or larger level of model complexity, the increase in loss before the second descent is more or less steep, or that the behavior of the test loss curve changes in some other way.</p> <p>These results can potentially be used by machine learning researchers and engineers to build more effective models. If we find that an ensemble model mitigates the increase in test loss or brings about a second descent sooner as we increase model size, that may be evidence in favor of using ensemble methods for different machine learning tasks, assuming that the additional resources used to build and train an ensemble model do not supersede the costs potentially saved by this method.</p> <hr/> <h2 id="related-work">Related Work</h2> <p>One of the first papers discussing double descent was Belkin et al. <d-cite key="belkin2019reconciling"></d-cite>. This paper challenged the traditional idea of the ‘bias-variance tradeoff’. They showed that after the interpolation threshold (where the model fits perfectly to the training data), test error eventually began to decrease once again.</p> <p>Nakkiran et al. <d-cite key="nakkiran2021deep"></d-cite> expanded these findings to the realm of <strong>deep</strong> learning. In this work, double descent is shown to occur for both large models and large datasets. Additionally this paper demonstrates that, counterintuitively, adding more data at a certain point actually worsened the performance of sufficiently large models. This highlights the need for a new understanding for model selection for effectively generalizing to testing datasets.</p> <p>In his classic paper ‘Bagging Predictors’ <d-cite key="breiman1996bagging"></d-cite>, Breiman describes the concept of combining the decisions of multiple models to improve classification ability. This bootstrap aggregating, or ‘bagging’ technique, reduced variance and improved accuracy, outperforming the single predictors that comprised the ensemble model.</p> <p>Another paper that discusses ensemble learning is Freund et al. <d-cite key="freund1997decision"></d-cite>, which introduced the Adaptive Boosting (AdaBoost) algorithm. On a high level, this paper illustrates how boosting is especially effective when combining weak learners that are moderately inaccurate to create a strong learner. We intend to use this algorithm as the basis of our ensemble methods.</p> <hr/> <h2 id="methods">Methods</h2> <p>For this project, we will be using the tool <code class="language-plaintext highlighter-rouge">make_classification</code> from sklearn.datasets to unearth the double descent phenomenon. At the moment, we intend to experiment with five models, as well as an ensemble of them: decision trees, random forest, logistic regression, support vector machines, and small neural networks. We choose these models because of their ability to be used for classification tasks, and more complicated models run the risk of exceeding Google Colab’s limitations, especially when we overparameterize these models to invoke double descent.</p> <p>We will describe methods of overfitting these five models below. However, based on feedback from course staff, we may change the models used for our experiments as necessary.</p> <h3 id="decision-trees">Decision Trees</h3> <p>To invoke double descent for decision trees, we can start with a small maximum depth of our tree, and increase this parameter until the training loss becomes perfect or near perfect.</p> <h3 id="random-forest">Random Forest</h3> <p>We can begin random forest with a small number of trees, and increase this until we see the double descent phenomenon in our test loss.</p> <h3 id="logistic-regression">Logistic Regression</h3> <p>To intentionally overfit using logistic regression, we can gradually increase the degree of the features. We can start with polynomial 1 and gradually increase this parameter.</p> <h3 id="support-vector-machines">Support Vector Machines</h3> <p>We will experiment with increasing the ’C’ parameter for SVM, which is inversely proportional to regularization of the model. By default, this is set as 1 in scikit-learn, but by increasing this, we can create a closer fit to the training data.</p> <h3 id="neural-networks">Neural Networks</h3> <p>We can start by initializing a neural network with a small number of layers and a small number of nodes per layer. We can then increase either or both of these two parameters to achieve perfect training loss, and hopefully a better test loss level.</p> <hr/> <h2 id="evaluation">Evaluation</h2> <p>To evaluate the performance of ensemble learning for mitigating the loss increase and expediting the second descent in overparameterized models, we can plot the loss difference between the ensemble loss curve and each individual model’s loss curve, where we plot loss over model size. We can report the statistical significance of this difference to judge the efficacy of using ensemble learning.</p> <h3 id="software">Software</h3> <p>To train and test these models, we will be using various machine learning packages in Python, such as Scikit-learn, PyTorch and Tensorflow. Additionally, to read in .csv datasets and clean them as necessary, we will be using data science packages such as pandas. Additional imports commonly used for machine learning project such as numpy and matplotlib will also be utilized.</p> <h3 id="datasets">Datasets</h3> <p>We plan on using <code class="language-plaintext highlighter-rouge">make_classification</code> from sklearn.datasets for our project to generate classification data. This tool is publicly available for experimentation and our use of it does not pose any ethical or copyright concerns.</p> <h3 id="computing-resources">Computing Resources</h3> <p>We will be implementing this project using CUDA and the free version of Google Colab. If these computational resources prove to be limiting for the original scope of our project, we can scale down the training time, model size, and dataset size as necessary, with the permission and guidance of course staff.</p> <h3 id="reproducibility-statement">Reproducibility Statement</h3> <p>To ensure reproducibility, we will save the seed that <code class="language-plaintext highlighter-rouge">make_classification</code> utilizes so that our results can be verified with the exact dataset we used. Additionally, we will provide our code in our final writeup.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/2023-11-08-double_descent.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>