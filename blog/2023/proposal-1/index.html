<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>6.S898 Project Proposal | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Exploring musical timbre transfer by leveraging prior art in differential digital signal processing (DDSP) and modern deep learning structures. Or, exploring techniques for running deep learning models on consumer-grade hardware and even microcontrollers."/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/proposal-1/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> </head> <d-front-matter> <script async type="text/json">{
      "title": "6.S898 Project Proposal",
      "description": "Exploring musical timbre transfer by leveraging prior art in differential digital signal processing (DDSP) and modern deep learning structures. Or, exploring techniques for running deep learning models on consumer-grade hardware and even microcontrollers.",
      "published": "November 9, 2023",
      "authors": [
        {
          "author": "Yohan Guyomard",
          "authorURL": "https://yohandev.github.io",
          "affiliations": [
            {
              "name": "MIT",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>6.S898 Project Proposal</h1> <p>Exploring musical timbre transfer by leveraging prior art in differential digital signal processing (DDSP) and modern deep learning structures. Or, exploring techniques for running deep learning models on consumer-grade hardware and even microcontrollers.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#meta-structure-of-this-proposal">(Meta) Structure of this Proposal</a></div> <div><a href="#idea-0-deep-learning-for-signal-processing">(Idea 0) Deep Learning for Signal Processing</a></div> <div><a href="#idea-1-deep-learning-for-the-modest-computer">(Idea 1) Deep Learning for the Modest Computer</a></div> </nav> </d-contents> <h2 id="meta-structure-of-this-proposal">(Meta) Structure of this Proposal</h2> <p>Hello! I have two directions for this project which I outline below; let me know how I could improve on either, or which is best suited for the class.</p> <h2 id="idea-0-deep-learning-for-signal-processing">(Idea #0) Deep Learning for Signal Processing</h2> <p>Exploring the use of deep learning models in signal processing, specifically with the musical application of timbre transfer. That is, transforming some audio clip while retaining every perceivable property except timbre (e.g. trumpet to violin). This exploration will largely build off <a href="https://magenta.tensorflow.org/ddsp">Magenta’s DDSP paper</a> from 2020 and consist of a digestible explanation of the concepts involved (spectrogram loss, harmonic oscillators, differentiable filters) and an alternative implementation using mechanisms taught in class. Some examples of this:</p> <ul> <li>Modify the encoder/decoder. Save for the DSP components, I think the architecture for this model can be very flexible (in layman’s terms, we are training a model to turn the knobs of a synth in realtime) so there’s a lot of room for play in between. <ul> <li>The original paper explicitely encodes pitch, amplitude and an (optional) time-dependent embedding, but is all of this needed? Do models perform better completely unsupervised?</li> </ul> </li> <li>The original paper uses GRUs just about everywhere, which makes sense, but could a transformer be useful here?</li> <li>Ditch additive synthesis altogether but retain the advantages of this paper with regard to neural audio synthesis (discussed therein). <ul> <li>Train a network to manipulate parameters on filters that operate on the source audio input? <ul> <li>Potential implementation: kind of like stable diffusion, randomly destroy the input signal (with additive noise but also [subtractive] DSP filters) and train a model to recover the original sound.</li> <li>Has the advantage of being much more faithful to the original signal (e.g. more expressivity) since the original paper’s encoder is rather reductive (pitch, amplitude)</li> </ul> </li> </ul> </li> </ul> <p>Regardless of which guiding question I pursue, this would make for a really fun interactive blog. The final submission will include an in-browser DSP that allows users to play with and form an intuition for what parameters the neural network is touching (e.g. an array of sliders for a harmonic oscillator).</p> <h2 id="idea-1-deep-learning-for-the-modest-computer">(Idea #1) Deep Learning for the Modest Computer</h2> <p>Overview of modern methods for adapting deep learning to consumer hardware and even microcontrollers. Demonstration of (faster, better?) alternatives to PyTorch, namely implemented in Rust. Large emphasis on quantization and how far it can be pushed. How practical is deep learning with fixed point arithmetic for platforms without FPUs (e.g. many microcontrollers). A slightly more defined plan for this:</p> <ul> <li>Quantization, or, billions of parameters running in the web (WebAssembly). In-depth explanation of how this works and has been used in LLMs like <code class="language-plaintext highlighter-rouge">llama.cpp</code>. Some exploration in extreme cases of this, e.g. is a 1 bit neural network any useful? <ul> <li>Adapting a large language model for the Raspberry Pi Pico, e.g. “GPT on $4” <ul> <li>Fixed point arithmetic… selective, or at every step?</li> <li>On a side note I’ve been working on <a href="https://yohandev.github.io/portfolio/picocraft/">pushing this hardware to its limits</a> so I have <em>(some)</em> faith that this is at all possible.</li> <li>If this works on the microcontroller, a similar web-demo would run at staggering speeds.</li> </ul> </li> </ul> </li> <li>Demonstration of novel deep learning frameworks, namely HuggingFace’s <code class="language-plaintext highlighter-rouge">candle</code>. There’s been a leap in ergonomic APIs in strongly-typed languages which already have so many advantages over Python. It’s also unlikely that PyTorch will ever run client-side web, let alone on embedded systems.</li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/2023-11-09-ddsp-proposal.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>