<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>blog - page 2 | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Staging website for the 2023 ICLR Blogposts track "/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/page/2/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="header-background"><div class="img"></div></div> <div class="container mt-5"> <div class="post"> <div class="header-bar"> <h1>6.S898 Deep Learning Blogs</h1> <h2>Fall 2023</h2> </div> <ul class="post-list"> <li> <h3> <a class="post-title" href="/staging/blog/2023/TransformersAndRNNs/">Transformers and RNNs: How do transformers implement recurrence?</a> </h3> <p></p> <p class="post-meta"> 5 min read &nbsp; &middot; &nbsp; November 9, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/SynCon/">Contrastive Learning with Dynamically Weighted Synthetic Images</a> </h3> <p>Final Project Proposal</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; November 9, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/Structural-vs-Data-Inductive-Bias/">Structural vs Data Inductive Bias</a> </h3> <p>Class project proposal</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 9, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/Robustness-of-self-supervised-ViT-features-in-b-mode-images/">Robustness of self supervised ViT features in b-mode images</a> </h3> <p>Project proposal for 6.S898 Deep Learning MIT class</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; November 9, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/PersonalizedGeneration_w_LLMAgents/">Personalizedgeneration_w_llmagents</a> </h3> <p></p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 9, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/Iterated-Representation-Learning/">Iterated Representation Learning</a> </h3> <p>Representation learning is a subfield of deep learning focused on learning meaningful lower-dimensional embeddings of input data, and rapidly emerging to popularity for its efficacy with generative models. However, most representation learning techniques, such as autoencoders and variational autoencoders, learn only one embedding from the input data, which is then used to either reconstruct the original data or generate new samples. This project seeks to study the utility of a proposed iterated representation learning framework, which repeatedly trains new latent space embeddings based on the data outputted from the last round of representation. In particular, we seek to examine whether the performance of this iterated approach on a model and input dataset are indicative of any robustness qualities of the model and latent embedding space, and potentially derive a new framework for evaluating representation stability.</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; November 9, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/Symmetry-Optimization/">Investigating the Impact of Symmetric Optimization Algorithms on Learnability</a> </h3> <p>Recent theoretical papers in machine learning have raised concerns about the impact of symmetric optimization algorithms on learnability, citing hardness results from theoretical computer science. This project aims to empirically investigate and validate these theoretical claims by designing and conducting experiments at scale. Understanding the role of optimization algorithms in the learning process is crucial for advancing the field of machine learning.</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 9, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/how-cnns-learn-shapes/">How CNNs learn shapes</a> </h3> <p></p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 9, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/Physics-Informed-Primal-Dual-Learning/">Physics-Informed Primal-Dual Learning</a> </h3> <p>Learning a deep net to optimize an LP, subject to both primal and dual hard constraints. Exploration of a novel proposed KKT-based training scheme.</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/quantum-gnn/">Quantum Circuit Optimization wtih Graph Neural Nets</a> </h3> <p>We propose a systematic study of architectural choices of graph nerual net-based reinforcement learning agents for quantum circuit optimization.</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/proposal-2/">6.S898 Project Proposal 2</a> </h3> <p>6.S898 project proposal for analyzing and evaluating the commonsense reasoning performance of multimodal vs text-only models.</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/multimodal-commonsense/">Multimodal Commonsense Proposal</a> </h3> <p>6.S898 project proposal for analyzing and evaluating the commonsense reasoning performance of multimodal vs text-only models.</p> <p class="post-meta"> 5 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/interpretability-of-toy-tasks/">Studying Interpretability of Toy Models on Algirithmic Tasks</a> </h3> <p>This blog makes the case for the importance of studying small models on easy algorithmic tasks, in order to understand larger and more complicated networks.</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/Structural_vs_Data_Inductive_Bias/">Structural vs Data Inductive Bias</a> </h3> <p>Class project proposal</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/spatiotemporal/">Project Proposal</a> </h3> <p>A survey of various embeddings for spatio-temporal forecasting.</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/sentence-embeddings/">Sentence Embeddings</a> </h3> <p>Large models, such as large language or vision models, are typically used to obtain embeddings of data, such as text or images. The embeddings are very rich and encode semantic information about the objects. The embeddings can be then later be used for tasks such as similarity search. However, the cost (both money and environmental) of obtaining the embeddings can be large. Given a dataset, can we query the model at 'very few points' which can later be extrapolated to embeddings for other data without querying the large model again?</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/scRNAseq-assumptions/">Examining assumptions in scRNA-seq foundation model pre-training (6.S898 Project Proposal)</a> </h3> <p>Initial proposal for a final project for MIT's Deep Learning (6.S898) class.</p> <p class="post-meta"> 6 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/project-blog/">Leveraging Representation Engineering to Evaluate LLMâ€™s Situational Awareness</a> </h3> <p>We present a method to tell whether LLMs are drawing from knowledge not explicitly mentioned in the prompt by examining token-level representations.</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/overpameterization/">Project Proposal</a> </h3> <p></p> <p class="post-meta"> 2 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/mapreason/">Reasoning with Maps: Assessing Spatial Comprehension on Maps in Pre-trained Models</a> </h3> <p>Assessing Spatial Comprehension on Maps in Pre-trained Models</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/interpreting-world-models/">Interpreting decision transformers - world models and feature</a> </h3> <p></p> <p class="post-meta"> 2 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/increasing-context-length-for-transformers/">6.S898 Project Proposal</a> </h3> <p>Increasing Context Length For Transformers</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/grokking-proposal/">Grokking Proposal</a> </h3> <p>What sparks the mysterious ''grokking'' in neural networks-a sudden leap in learning beyond training? This proposal outlines our blog's mission to investigate this perplexing event. We're set to explore the triggers and theories behind grokking, seeking to understand how and why these moments of unexpected intelligence occur.</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/finetune-jailbreak/">Finetuning a Language Model to Jailbreak Itself</a> </h3> <p>Recent work has focused heavily on aligning language models to ensure they don't output harmful text. I propose a new set of experiments to finetune a language model to jailbreak a copy of itself and present preliminary results.</p> <p class="post-meta"> 10 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/double_descent/">Dynamic Ensemble Learning for Mitigating Double Descent</a> </h3> <p>Exploring when and why Double Descent occurs, and how to mitigate it through Ensemble Learning.</p> <p class="post-meta"> 8 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/diaz-proposal/">Vision Transformers: High-Frequency means High-Fidelity</a> </h3> <p>Vision Transforms have a quadratic complexity for the patch length. Past work have circumnavigated this complexity at the cost of losing information. Recent advances propose ViT amendments serving to preserve global attention and high-frequency information - all with a lowered computational burden. Here, we propose to investigate the translation of such architectures to a longstanding image restoration problem: MRI.</p> <p class="post-meta"> 5 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/detect-image/">Zero-Shot Machine-Generated Image Detection using Sinks of Gradient Flows</a> </h3> <p>How can we detect fake images online? A novel approach of characterizing the behavior of a diffusion model's learned score vectors.</p> <p class="post-meta"> 5 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/denoising-EMG-signals/">Denoising EMG signals</a> </h3> <p>The future of brain-computer interfaces rests on our ability to decode neural signals. Here we attempt to ensemble ML techniques to extract useful information from sEMG signals to improve downstream task performance.</p> <p class="post-meta"> 2 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/croneillproposal/">How to learn a linear representation of a dynamical system</a> </h3> <p>A final project proposal for 6.s898 in fall 2023</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="/staging/blog/2023/WeightDecaySpecNormEffects/">Exploring Weight decay and Spectral Normalization in MLPs and Residual networks</a> </h3> <p>Project proposal for Spectral normalization related final project for 6.s898, Fall 2023.</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; November 8, 2023 </p> <p class="post-tags"> <a href="/staging/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item "> <a class="page-link" href="/staging/blog/" tabindex="-1" aria-disabled="1">Newer</a> </li><li class="page-item "><a class="page-link" href="/staging/blog/index.html" title="blog">1</a></li> <li class="page-item active"><a class="page-link" href="/staging/blog/page/2/index.html" title="blog - page 2">2</a></li> <li class="page-item "><a class="page-link" href="/staging/blog/page/3/index.html" title="blog - page 3">3</a></li> <li class="page-item "> <a class="page-link" href="/staging/blog/page/3/">Older</a> </li> </ul> </nav> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/staging/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/staging/assets/js/zoom.js"></script> <script defer src="/staging/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>