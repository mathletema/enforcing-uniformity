<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Contrastive Time Series Representation Learning | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Proposal for a new method of time series representation learning"/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2022/contrastive-time/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "Contrastive Time Series Representation Learning",
      "description": "Proposal for a new method of time series representation learning",
      "published": "November 7, 2022",
      "authors": [
        {
          "author": "Martin Ma",
          "authorURL": "https://www.linkedin.com/in/martinzwm/",
          "affiliations": [
            {
              "name": "Harvard University",
              "url": ""
            }
          ]
        },
        {
          "author": "Lily Wang",
          "authorURL": "https://www.linkedin.com/in/xiaochen-lily-wang-175897183/",
          "affiliations": [
            {
              "name": "Harvard University",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Contrastive Time Series Representation Learning</h1> <p>Proposal for a new method of time series representation learning</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#objectives">Objectives</a></div> <div><a href="#hypothesis">Hypothesis</a></div> <div><a href="#experimental-setup">Experimental Setup</a></div> <div><a href="#conclusion">Conclusion</a></div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>Time-series data analysis is pivotal in numerous scientific and industrial applications, including dynamical system, weather forecasting, and stock market prediction. The underlying parameters governing the time-series data can often be complex and not directly observable. Unlike traditional time series approaches, which predominantly focus on prediction tasks, leading to a “black-box” prediction <d-cite key="Lim_2021"></d-cite>. Recent literatures have explored using contrastive learning to learn time-series representation, but none has explored learning underlying system parameters <d-cite key="eldele2021timeseries"></d-cite>. In this project, we want to leverage the contrastive learning approach studied in class to learn underlying system parameters parameters.</p> <p>A deep comprehension of these underlying parameters, if successfully achieved, can lead to 2 benefits - 1) enhanced model capability for making accurate future predictions, and 2) a better understanding of the underlying system. The latter is particularly important in scientific, where the goal is to understand the underlying system, and engineering, where safety and reliability are of paramount importance.</p> <p>To achieve the above goals, we proposed the following experiments and setups to study the insights of using contrastive approach to learn latent parameters for time-series representation.</p> <h2 id="objectives">Objectives</h2> <p>The primary objective of this research is to investigate the effectiveness of contrastive loss learning in capturing the system underlying parameters (\(\theta_i\)) of time-series data. We aim to:</p> <ol> <li>Test the capability of contrastive learning approach to extract embeddings from time-series data that correlate strongly with system underlying parameters.</li> <li>Study different neural network architecture for encoding time-series trajectories into informative embeddings.</li> <li>Explore the impact of various factors such as function forms, number of parameters and distributions, trajectory length, noise levels, and loss functions on the model’s performance.</li> <li>Evaluate the precision of the predictive models in terms of their ability to make accurate future predictions based on learned latent variables, particularly in few-shot learning scenarios.</li> </ol> <h2 id="hypothesis">Hypothesis</h2> <p>With contrastive loss learning, the embeddings of trajectories from the same parameter set will be closer together in the embedding space than to those from different sets. Therefore, our central hypothesis is that the embeddings produced by a model trained with contrastive loss learning will reflect the underlying parameters of time-series data. It is anticipated that a linear projection of these embeddings back onto the parameter space will yield predictions that are congruent with the original parameter values. Moreover, we postulate that the model will be able to make more precise future predictions by effectively capturing the essence of the latent variables governing the time-series data.</p> <h2 id="experimental-setup">Experimental Setup</h2> <h3 id="trajectories-simulation">Trajectories Simulation</h3> <p>We will generate synthetic time-series data based on underlying deterministic and stochastic processes (e.g., spring-mass dynamical system).</p> <ul> <li>The system can be defined by a set of parameters \(\theta_i\). We have $H$ set of parameters.</li> <li>For each set of parameters, a trajectory, \(\{x_{ij}\}\) of length $T$ can be draw with different initial conditions and noise. We will sample $K$ trajectories for each set of parameters.</li> </ul> <h3 id="models">Models</h3> <p>We will evaluate three different neural network architectures:</p> <ol> <li>Recurrent Neural Network (RNN)</li> <li>Long Short-Term Memory (LSTM)</li> <li>Transformer (utilizing attention mechanisms)</li> </ol> <p>A model \(M\) will output an embedding vector \(v_{ij}\) for a given input trajectory \(\{x_{ij}\}\).</p> <h3 id="experimentation">Experimentation</h3> <p>We want to evaluate the contrastive approach in extracting system parameter under the following scenarios:</p> <ol> <li><strong>System Functional Forms:</strong> We will test linear, non-linear, and complex periodic functions to generate the trajectories.</li> <li><strong>Number of Parameters (\(\lvert \theta \rvert\)):</strong> We will explore varying the number of parameters to understand how it affects the model’s ability to learn.</li> <li><strong>Parameter Distribution:</strong> We will use different distributions (uniform, normal, bimodal, etc.) of parameters (i.e., $\theta_i$) to study the impact on the learning process.</li> <li><strong>Trajectory Length (\(T\)):</strong> We will vary the length to assess the effect on the model’s performance.</li> <li><strong>Noise Levels:</strong> Different amounts of Gaussian noise will be added to the trajectories to simulate real-world data imperfections.</li> <li><strong>Loss Functions:</strong> Alongside contrastive loss, does add a loss function for model prediction of next time stamp help performance?</li> </ol> <h2 id="conclusion">Conclusion</h2> <p>This proposal presents a structured plan to investigate the potential of contrastive loss approach in learning system underlying parameters of time-series data. The insights gained from this research could pave the way for advancements in various fields where time-series analysis is crucial. We hope the insights from our project can contribute to the field of machine learning and its applications in time-series analysis.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/2023-11-08-contrastive-time.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>